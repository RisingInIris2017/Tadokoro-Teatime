# 第一讲-神经网络
## 什么是神经网络
神经元组成的网络。

对神经元建模：

多个加权输入，一个判断门限，一个输出。
## 什么是人工神经网络
### 人工神经元
建立人工神经元函数 function

`function(bias+&Sigma;weight*input)`

如果 function 的值达到门限，输出 `output`。
### 建立人工神经网络
将神经元输出个数增加，增加后称为一层（Layer）。
将多层级联排列，就得到人工神经网络。

## 人工神经网络举例
### 专家系统
输入一张手写体阿拉伯数字的灰度图片，例如 18x18 的尺寸。

将其向量化为 324 维的向量，输入手写体数字辨识网络。

则输入神经元有 126 个，输出神经元有 0-9 共 10 个。

人为配置各个权重的值，就形成一个手写体阿拉伯数字图片，到数字的专家系统。

### 机器学习
机器学习的任务是学习权重值 `weight` 的值。

由于 `weight` 的数量巨大，

人为设定是很困难的，需要借助机器学习。

本质上机器学习的任务，就是*函数拟合* ，

从原始的数据出发，*逼近* 我们所需的函数。

可供参考的资料：

1. [TensorFlow 玩具程序](playground.tensorflow.org)

2. [Neural Networks and Deep Learning.com](neuralnetworksanddeeplearning.com)

## 构造神经网络的范例：函数拟合
### 目标
构造神经网络，拟合一个形状不规则的一元函数 y=f(x)
### 激活函数
#### Sigmoid 函数
sigmoid(x) = 1/(1+exp(x))

在 x 的绝对值很大的情况下，函数值趋向于 0 和 1。

但是在 x 的绝对值很小的情况下，函数值的变化比较剧烈。
#### 利用 Sigmoid 函数构造实用的激活函数
令

`modifiedx = weight * x + bias`

然后构造 sigmoid(modifiedx) 函数作为激活函数。

weight 绝对值越大，sigmoid 函数越陡峭，对输入值越敏感。

weight 的符号决定函数的变化方向，正的表示增函数，负的表示减函数。

bias 决定 sigmoid 函数的中心点，

中心点的坐标为(-bias/weight,0.5)。

规定变量

`s = -bias/weight`

则 s 可以唯一描述 sigmoid 函数。

#### 用激活函数逼近任意函数
用一增一减两个激活函数构造冲激函数；

用足够多的冲激函数来逼近原函数。
